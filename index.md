<!--
**KimManjin/KimManjin** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

I'm Manjin Kim, a Ph.D student in [Pohang University of Science and Technology (POSTECH)](https://www.postech.ac.kr/eng/), South Korea. I am a member of the [computer vision lab](http://cvlab.postech.ac.kr/lab/) at POSTECH, under supervision of Professor [Minsu Cho](http://cvlab.postech.ac.kr/~mcho/). My research interest is in learning video representation and its applications.

---------------------------------------------

## Research Interests
* Video representation learning
* Motion feature learning
* Multi-modal learning

---------------------------------------------

## Publications
- **Exploring High-Order Self-Similarity for Video Understanding**  
  **Manjin Kim**, Heeseung Kwon, Karteek Alahari, and Minsu Cho, _under_ _review_.
- **Generic Event Boundary Detection via Denoising Diffusion**  
  Jaejun Hwang\*, Dayoung Gong\*, **Manjin Kim**, Minsu Cho (* equal contribution), _under_ _review_.
- **[Learning correlation structures for vision transformers](https://arxiv.org/abs/2404.03924)** &#91;[project page](https://kimmanjin.github.io/structsa/)&#93; &#91;<span style="color:#0366d6">code</span>&#93;  
  **Manjin Kim**, Paul Hongsuck Seo\*, Cordelia Schmid, and Minsu Cho\* (* corresponding authors), _CVPR_ 2024.
- **[Future transformer for long-term action anticipation](https://arxiv.org/abs/2205.14022)** &#91;[project page](http://cvlab.postech.ac.kr/research/FUTR/)&#93; &#91;[code](https://github.com/gongda0e/FUTR)&#93;  
  Dayoung Gong, Joonseok Lee, **Manjin Kim**, Seongjong Ha, and Minsu Cho, _CVPR_ 2022.
- **[Relational self-attention: what's missing in attention for video understanding](https://arxiv.org/abs/2111.01673)** &#91;[project page](http://cvlab.postech.ac.kr/research/RSA/)&#93; &#91;[code](https://github.com/KimManjin/RSA)&#93;  
  **Manjin Kim\***, Heeseung Kwon\*, Chunyu Wang, Suha Kwak, and Minsu Cho (* equal contribution), _NeurIPS_ 2021.     
- **[Learning self-similarity in space and time as as generalized motion for video action recognition](https://arxiv.org/abs/2102.07092)** &#91;[project page](http://cvlab.postech.ac.kr/research/SELFY/)&#93; &#91;[code](https://github.com/arunos728/SELFY)&#93;  
  Heeseung Kwon\*, **Manjin Kim\***, Suha Kwak, and Minsu Cho (* equal contribution), _ICCV_ 2021.
- **[MotionSqueeze: neural motion feature learning for video understanding](https://arxiv.org/abs/2007.09933)** &#91;[project page](http://cvlab.postech.ac.kr/research/MotionSqueeze/)&#93; &#91;[code](https://github.com/arunos728/MotionSqueeze)&#93;  
  Heeseung Kwon, **Manjin Kim**, Suha Kwak, and Minsu Cho, _ECCV_ 2020.

---------------------------------------------

## Industry experiences
- **Student Researcher**, [Google Research]([https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/](https://research.google/)), France (Jul. 2022 - Jan. 2023)
    + Developed a multimodal long-form video captioning system.
    + Host: [Paul Hongsuck Seo](https://phseo.github.io/)
- **Research Intern**, [Microsoft Research Asia (MSRA)](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/), remote (Dec. 2020 - June. 2021)
    + Developed a dynamic neural feature transform method, called Relational Self-Attention.
    + Mentor: [Chunyu Wang](https://www.microsoft.com/en-us/research/people/chnuwa/)
- **Research Intern**, [LG CNS](https://www.lgcns.com/EN/Home), Korea (Jun. 2018 - Aug. 2018)
    + Developed a video data augmentation system using CycleGAN.

---------------------------------------------

## Collaboration projects
- **Motion-centric video representation learning** (with [Google Research](https://research.google/))
    + Developed vision transformers, dubbed StructViT, that effectively learn spatial(-temporal) correlation structures for both image and video understanding.
- **Online action detection in streamed videos** (with [POSCO ICT](https://www.poscoict.com/servlet/Main?lang=en))
    + Developed a real-time action recognition system for video surveillance.
- **Sentimental analysis on Hyundai vehicle models** (with [Hyundai Motor Company](https://www.hyundai.com/kr/en/main))
    + Analyzed a sentiment of Hyundai vehicle models from comments on web communities.

---------------------------------------------

## Education
- **[Pohang University of Science and Technology](http://postech.ac.kr/eng/)**, Pohang, Korea (2019.09 - present)  
  \- Integrated M.S./Ph.D. in [Convergence IT Engineering](https://cite.postech.ac.kr/)  
  \- Advisor: Prof. [Minsu Cho](http://cvlab.postech.ac.kr/~mcho/)
- **[Pohang University of Science and Technology](http://postech.ac.kr/eng/)**, Pohang, Korea (2013.03 - 2019.02)  
	\- B.S. in [Convergence IT Engineering](https://cite.postech.ac.kr/)  
	\- Advisor: Prof. [Sangwoo Kim](https://icsl.postech.ac.kr/)
