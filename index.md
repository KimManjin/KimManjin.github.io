<!--
**KimManjin/KimManjin** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

I'm Manjin Kim, a Ph.D student in [Pohang University of Science and Technology (POSTECH)](https://www.postech.ac.kr/eng/), South Korea. I am a member of the [computer vision lab](http://cvlab.postech.ac.kr/lab/) at POSTECH, under supervision of Professor [Minsu Cho](http://cvlab.postech.ac.kr/~mcho/). My research interest is in learning video representation and its applications.

-------------
#### Research Interests
* Video representation learning
* Motion feature learning
* Multi-modal learning

#### Publications
* Heeseung Kwon, **Manjin Kim**, Suha Kwak, and Minsu Cho, MotionSqueeze: neural motion feature learning for video understanding, _ECCV_, 2020. [paper](https://arxiv.org/abs/2007.09933) [code](https://github.com/arunos728/MotionSqueeze)
* Heeseung Kwon*, **Manjin Kim***, Suha Kwak, and Minsu Cho, Learning self-similarity in space and time as as generalized motion for video action recognition, _ICCV_, 2021.   (* equal contribution) [paper](https://arxiv.org/abs/2102.07092) [code](https://github.com/arunos728/SELFY)
* **Manjin Kim***, Heeseung Kwon, Chunyu Wang, Suha Kwak, and Minsu Cho, Relational self-attention: what's missing in attention for video understanding, _NeurIPS_, 2021.   (* equal contribution) [paper](https://arxiv.org/abs/2111.01673) [code](https://github.com/KimManjin/RSA)

#### Industry experience
* LG CNS, Research Intern, Jun 2018 - Aug 2018
* Microsoft Research Asia (MSRA), Research Intern, Dec 2020 - June 2021
